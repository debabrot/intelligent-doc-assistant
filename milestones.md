## ğŸ—“ï¸ Week-by-Week Plan

### ğŸ”¹ **Week 1: Project Setup & Ingestion MVP**

**Goal**: Load a PDF and store chunks in Chroma.

**Tasks**:
- Set up Python environment (venv, pip)
- Install: `langchain`, `chromadb`, `unstructured`, `PyPDF2`, `sentence-transformers`
- Write script to:
  - Load a PDF
  - Split into chunks
  - Embed with `all-MiniLM-L6-v2`
  - Store in Chroma (persistent mode)

**Deliverable**: `ingestion-demo.py` that ingests `sample.pdf` â†’ `vector_db/chroma/`

**Validation**:
```python
retriever.similarity_search("What is the API key policy?")
```
â†’ Returns relevant chunks

---

### ğŸ”¹ **Week 2: Build Ingestion Service (FastAPI + Upload)**

**Goal**: Turn ingestion into a web service with file upload.

**Tasks**:
- Create `services/ingestion-service/`
- Build FastAPI app with:
  - `POST /upload` â†’ saves file to `data/raw/`
  - Sync indexing (for now, sync processing)
- Add basic file validation (PDF, MD, TXT)

**Deliverable**: Running FastAPI server at `http://localhost:8001/upload`

**Validation**:
```bash
curl -X POST -F "file=@sample.pdf" http://localhost:8001/upload
```
â†’ File appears in `data/raw/`, chunks in Chroma

---

### ğŸ”¹ **Week 3: Add Async Processing & Chunking Strategies**

**Goal**: Make ingestion async and support multiple formats.

**Tasks**:
- Add **Celery + Redis** (use docker-compose)
- Move processing to `tasks/process_document.py`
- Support:
  - PDF (text + OCR for scanned)
  - Markdown (with header splitting)
  - TXT
- Add meta `source`, `page`, `type`

**Deliverable**: Upload â†’ async job â†’ processed â†’ indexed

**Validation**:
- Upload scanned PDF â†’ OCR extracts text â†’ indexed
- Upload MD â†’ preserves `# API Docs` headers in metadata

---

### ğŸ”¹ **Week 4: Build Query Service & LLM Integration**

**Goal**: Answer questions using retrieved context.

**Tasks**:
- Create `services/query-service/`
- Build:
  - `POST /query` â†’ uses Chroma + LLM
  - Use **Ollama + Llama 3** for generation
  - Simple retrieval â†’ prompt â†’ answer
- Test with real questions

**Deliverable**: `http://localhost:8000/query` returns answers

**Validation**:
```json
POST /query
{"question": "How do I reset my password?"}
â†’ "To reset your password, go to Settings > Account..."
```

---

### ğŸ”¹ **Week 5: Add Advanced RAG Features**

**Goal**: Go beyond basic RAG with hybrid search, re-ranking, and query rewrite.

**Tasks**:
- Implement **Hybrid Search**:
  - Vector (Chroma) + BM25 (rank-bm25)
  - Combine with **RRF (Reciprocal Rank Fusion)**
- Add **Re-Ranking**:
  - Use `cross-encoder/ms-marco-MiniLM-L-6-v2`
- Add **Query Transformation**:
  - HyDE: generate hypothetical answer â†’ embed
  - Or simple rewrite: â€œHow to reset?â€ â†’ â€œsteps to reset passwordâ€

**Deliverable**: Better retrieval â†’ better answers

**Validation**:
- Query: â€œWhatâ€™s the auth flow?â€ â†’ retrieves OAuth diagram + text
- Before: 2/5 relevant chunks â†’ After: 5/5

---

### ğŸ”¹ **Week 6: Frontend, Feedback & Deployment**

**Goal**: Ship a usable, monitored system.

**Tasks**:
- Build `ui/app.py` with **Gradio**:
  - Chat interface
  - File upload
  - Thumbs up/down
- Add `POST /feedback` endpoint
- Log feedback to `feedback.log` or SQLite
- Dockerize both services
- Deploy to **Fly.io** or **Railway**

**Deliverable**: Publicly accessible demo!

**Validation**:
- Share link with a friend â†’ they upload a doc â†’ ask a question â†’ get answer
- You see feedback logged

---

## ğŸš€ Bonus (Week 7â€“8, Optional)

| Feature | Value |
|-------|-------|
| **Self-Correction** | Analyze low-rated queries â†’ improve chunking/query rewrite |
| **Monitoring** | Prometheus + Grafana: track latency, retrieval quality |
| **CI/CD** | GitHub Actions: test + deploy on push |
| **Multi-Modal** | Extract images from PDF â†’ embed with CLIP â†’ retrieve on â€œsee diagramâ€ |
| **Replace Ollama â†’ Bedrock** | Use `BedrockLLM` provider in production |

---

# ğŸ“ Final Project Structure (Updated)

```bash
intelligent-doc-assistant/
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ query-service/          # FastAPI: /query, /feedback
â”‚   â””â”€â”€ ingestion-service/      # FastAPI: /upload, async processing
â”œâ”€â”€ shared/                     # Reusable models, utils, vectorstore
â”œâ”€â”€ ui/                         # âœ… Frontend: Gradio app
â”‚   â””â”€â”€ app.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Uploaded files
â”‚   â””â”€â”€ processed/              # OCR'd, chunked
â”œâ”€â”€ vector_db/chroma/           # Persistent vector store
â”œâ”€â”€ prefect_flows/              # Optional: sync from GitHub
â”œâ”€â”€ monitoring/                 # Prometheus/Grafana configs
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md                   # Project overview, how to run
```

---

# ğŸ› ï¸ Tools Youâ€™ll Use

| Purpose | Tool |
|-------|------|
| Backend | FastAPI |
| Frontend | Gradio |
| LLM | Ollama (Llama 3) |
| Embedding | Sentence Transformers |
| Vector DB | Chroma |
| Async | Celery + Redis |
| Container | Docker + docker-compose |
| Hosting | Fly.io / Railway (free tier) |
| CI/CD | GitHub Actions |
| Monitoring | Prometheus + Grafana Cloud (free) |

---

# ğŸ Final Deliverables (Portfolio-Ready)

By the end, youâ€™ll have:

âœ… A **working RAG system** with advanced features  
âœ… A **modular microservices architecture**  
âœ… A **public demo** (Gradio + hosted API)  
âœ… **Clean, documented code** on GitHub  
âœ… **MLOps practices**: logging, monitoring, CI/CD  
âœ… A **README** with screenshots, architecture diagram, and setup guide

---

# ğŸ’¡ Pro Tip: Document Your Journey

As you build:
- Take **screenshots** of UI, retrieval results
- Record a **short Loom video** demo
- Write a **blog post** or LinkedIn post: â€œHow I built an AI document assistantâ€

This will **amplify your visibility** and help you land interviews.

---

## FULL DIRECTORY STRUCTURE
intelligent-doc-assistant/
â”‚
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ query-service/                 # FastAPI: handles /query
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”‚   â”œâ”€â”€ query_router.py
â”‚   â”‚   â”‚   â””â”€â”€ feedback_router.py
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ retrieval_service.py   # Hybrid search, re-ranking
â”‚   â”‚   â”‚   â””â”€â”€ llm_service.py         # LLM abstraction
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â”œâ”€â”€ request.py
â”‚   â”‚   â”‚   â””â”€â”€ response.py
â”‚   â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”‚   â”œâ”€â”€ settings.py            # Config via env vars
â”‚   â”‚   â”‚   â””â”€â”€ constants.py
â”‚   â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”‚   â”œâ”€â”€ logger.py
â”‚   â”‚   â”‚   â””â”€â”€ metrics.py
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â”‚
â”‚   â”œâ”€â”€ ingestion-service/             # FastAPI: handles /upload
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”‚   â””â”€â”€ upload_router.py
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ ingestion_service.py   # Load, chunk, embed
â”‚   â”‚   â”‚   â””â”€â”€ indexing_service.py    # Update vector DB
â”‚   â”‚   â”œâ”€â”€ workers/
â”‚   â”‚   â”‚   â””â”€â”€ celery_worker.py       # Async processing
â”‚   â”‚   â”œâ”€â”€ tasks/
â”‚   â”‚   â”‚   â””â”€â”€ process_document.py    # Celery task
â”‚   â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”‚   â””â”€â”€ storage.py             # S3, local, etc.
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â”‚
â”‚   â””â”€â”€ llm-service/ (optional future) # Unified LLM API
â”‚       â””â”€â”€ ...
â”‚
â”œâ”€â”€ shared/
â”‚   â”œâ”€â”€ vectorstore/                   # Chroma wrapper
â”‚   â”‚   â”œâ”€â”€ client.py
â”‚   â”‚   â””â”€â”€ hybrid_retriever.py
â”‚   â”œâ”€â”€ models/                        # Shared embedding/LLM logic
â”‚   â”‚   â”œâ”€â”€ embeddings.py              # BGE, MiniLM
â”‚   â”‚   â”œâ”€â”€ reranker.py                # Cross-encoder
â”‚   â”‚   â””â”€â”€ multimodal.py              # CLIP, OCR
â”‚   â”œâ”€â”€ schemas/                       # Pydantic models
â”‚   â”‚   â”œâ”€â”€ document.py
â”‚   â”‚   â””â”€â”€ chunk.py
â”‚   â””â”€â”€ utils/                         # Shared helpers
â”‚       â”œâ”€â”€ file_utils.py
â”‚       â””â”€â”€ monitoring.py
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                           # Uploaded files
â”‚   â””â”€â”€ processed/                     # Chunked, OCR'd
â”‚
â”œâ”€â”€ vector_db/
â”‚   â””â”€â”€ chroma/                        # Persistent Chroma DB
â”‚
â”œâ”€â”€ prefect_flows/
â”‚   â””â”€â”€ scheduled_ingest.py            # Daily sync from GitHub, etc.
â”‚
â”œâ”€â”€ monitoring/
â”‚   â”œâ”€â”€ prometheus/
â”‚   â””â”€â”€ grafana/                       # Dashboard config
â”‚
â”œâ”€â”€ docker-compose.yml                 # Or Kubernetes later
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

## QWEN CHAT LINK
https://chat.qwen.ai/c/be8c44c9-8ab1-4b0c-93f3-c50114cf33f3
